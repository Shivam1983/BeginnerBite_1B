# BeginnerBytes - Persona-Driven PDF Intelligence (Adobe Hackathon 2025)

**Team Name:** beginnerbytes
**Members:** Revanth, Shivam, Ashutosh
**Challenge:** Adobe India Hackathon - Connecting the Dots (Round 1B)

Build a smart document intelligence system that extracts and ranks the most relevant sections/sub-sections from a PDF collection based on a specific persona and job-to-be-done.

---

## ğŸ“š Table of Contents

* [ğŸ“Œ Problem Statement](#-problem-statement)
* [ğŸ§  Key Features](#-key-features)
* [ğŸ›  Tech Stack](#-tech-stack)
* [ğŸ“ Project Directory Structure](#-project-directory-structure)
* [ğŸ§­ System Architecture](#-system-architecture)
* [âš™ Setup & Installation](#-setup--installation)
* [ğŸ‹ Training the Ranker](#-training-the-ranker)
* [ğŸš€ Inference Execution](#-inference-execution)
* [ğŸ³ Docker Usage](#-docker-usage)
* [âœ… Constraints & Compliance](#-constraints--compliance)
* [ğŸ¯ Contributions](#-contributions)
* [ğŸ”® Future Improvements](#-future-improvements)
* [ğŸ“¬ Contact & Support](#-contact--support)

---

## ğŸ“Œ Problem Statement

In Round 1B, we were required to build a system that:

1. Takes **3â€“10 PDF documents** as input
2. Accepts a **persona description** and a **job-to-be-done**
3. **Analyzes and extracts** the most relevant sections & sub-sections from the documents
4. Returns a **ranked JSON output** as follows:

```json
{
  "metadata": {
    "input_documents": [...],
    "persona": "...",
    "job_to_be_done": "...",
    "timestamp": "YYYY-MM-DDThh:mm:ssZ"
  },
  "selected_sections": [
    { "document": "doc1.pdf", "page": 2, "section_title": "Methodology", "importance_rank": 1 }
  ],
  "selected_subsections": [
    { "document": "doc2.pdf", "page": 5, "subsection_title": "Findings", "importance_rank": 1 }
  ]
}
```

---

## ğŸ§  Key Features

* Reuses structured output from **Round 1A** (outline with headings)
* Uses **semantic embeddings** from `all-MiniLM-L6-v2` (Sentence Transformers)
* Computes **cosine similarity** between query (persona+job) and section embeddings
* Trains a **Random Forest Ranker** on handcrafted relevance data
* Outputs top N sections and sub-sections with `importance_rank`
* Fully **offline**, **Docker-compatible**, and **modular**

---

## ğŸ›  Tech Stack

* Python 3.10
* Sentence-Transformers
* scikit-learn
* PyMuPDF (fitz)
* Pandas, NumPy, Joblib
* Click (CLI)
* Docker

---

## ğŸ“ Project Directory Structure

```bash
BeginnerBytes_1B/
â”œâ”€â”€ app.py                      # Entrypoint for app execution
â”œâ”€â”€ main.py                     # CLI runner
â”œâ”€â”€ Dockerfile                  # AMD64-compatible Docker config
â”œâ”€â”€ docker-compose.yml          # Optional compose support
â”œâ”€â”€ requirements.txt            # Project dependencies
â”œâ”€â”€ requirements-lite.txt       # Lightweight dependency version
â”œâ”€â”€ .gitignore                  # Ignore virtual env, data, models, etc.
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ round1b_relevance_data.json      # Labeled training data (persona-task-section)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ heading_model.joblib            # Round 1A heading detector
â”‚   â”œâ”€â”€ relevance_ranker.joblib         # Trained section ranker
â”‚   â””â”€â”€ sentence_transformer_model/     # all-MiniLM-L6-v2 downloaded locally
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ vocab.txt
â”‚       â””â”€â”€ ... (other transformer config files)
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ sample1_output.json
â”‚   â”œâ”€â”€ sample2_output.json
â”‚   â””â”€â”€ sample3_output.json
â”‚
â”œâ”€â”€ pdfs_input/
â”‚   â”œâ”€â”€ sample1/
â”‚   â”œâ”€â”€ sample2/
â”‚   â””â”€â”€ sample3/
â”‚
â”œâ”€â”€ processing_data/
â”‚   â””â”€â”€ relevance_training_data.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ sentence_transformer_model.py  # Sentence embedding utilities
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ round1a_deps/                  # Modules reused from Round 1A
â”‚   â””â”€â”€ round1b/
â”‚       â”œâ”€â”€ document_analyzer.py
â”‚       â”œâ”€â”€ relevance_model.py
â”‚       â”œâ”€â”€ text_chunker.py
â”‚       â””â”€â”€ train_ranker.py
```

---

## ğŸ§­ System Architecture

```
[Persona + Job] â†’ Query Embedding
       â†“
     [PDFs] â†’ Section Extraction (Round 1A)
       â†“
  Section Chunking
       â†“
  Section Embedding
       â†“
(Embeddings + Cosine Similarity + Level)
       â†“
 RandomForest Ranker
       â†“
 Rank & Filter Top N
       â†“
 Final JSON Output
```

---

## âš™ Setup & Installation

```bash
git clone <repo_url> && cd BeginnerBytes_1B
python -m venv venv
source venv/bin/activate  # or activate.bat for Windows
pip install -r requirements.txt
```

### Download Sentence Transformer

```bash
from sentence_transformers import SentenceTransformer
SentenceTransformer('all-MiniLM-L6-v2').save_pretrained('models/sentence_transformer_model')
```

---

## ğŸ‹ Training the Ranker

```bash
python src/round1b/train_ranker.py \
  --input data/round1b_relevance_data.json \
  --output models/relevance_ranker.joblib
```

---

## ğŸš€ Inference Execution

```bash
python src/main.py data/input_pdfs/sample1 output/
```

Repeat for each sample folder (sample2/, sample3/, etc.)

---

## ğŸ³ Docker Usage

```bash
# Build
docker build --platform linux/amd64 -t beginnerbytes_1b:latest .

# Run
docker run --rm -v "$(pwd):/app" --network none beginnerbytes_1b:latest data/input_pdfs/sample1 output/
```

---

## âœ… Constraints & Compliance

| Requirement          | Our Solution                  |
| -------------------- | ----------------------------- |
| â± Execution Time     | â‰¤ 60 sec (passes)             |
| ğŸ“¦ Model Size        | â‰¤ 1 GB (uses \~200MB)         |
| ğŸ”Œ Offline Execution | Enforced via `--network none` |
| âš™ CPU Only           | Docker AMD64 base image       |

---

## ğŸ¯ Contributions

* Integrated Round 1A output as feature input
* Combined semantic + structural features for ranking
* Modular pipeline with reproducible outputs
* Fully offline Dockerized solution

---

## ğŸ”® Future Improvements

* Enhance training set diversity for better generalization
* Add visual UI for interacting with results
* Test with scanned PDFs (OCR)
* Adopt transformer-based ranking (e.g., cross-encoders)

---

## ğŸ“¬ Contact & Support

Reach out to: **[revanthkurapati2004@gmail.com](mailto:revanthkurapati2004@gmail.com)**
If you found this project useful, please **ğŸŒŸ star** the repository!
